{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierarchical modeling and k mode \n",
    "#used the most granular information from v3\n",
    "#used the top 150 common features from v3 \n",
    "#also limited sample size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import metrics#import editdistance as edist\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from scipy import cluster\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in v3 data which is a dictionary of aa and what do they stand for\n",
    "df =pd.read_csv('~/Documents/persona_project_cardiology/clustering/persona1_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in name for each segment \n",
    "names=pd.read_csv('~/Documents/persona_project_cardiology/clustering/names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.iloc[:,8:]\n",
    "#eliminate the first 8 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make it run faster, only look at the first 150 features, and the most reacent 20000 rows \n",
    "df2=df1.iloc[:20000,:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 30)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detecting outliers in outcomes\n",
    "#isf=IsolationForest()\n",
    "#isf.fit(df2)\n",
    "#t=isf.predict(df2)\n",
    "#len(np.where(t==-1)[0])\n",
    "#df3=df2[t==1]\n",
    "\n",
    "df3=df2\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierarchical clustering with custome distance/dissimilarity metric\n",
    "#https://gist.github.com/codehacken/8b9316e025beeabb082dda4d0654a6fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change data type from int to boolean to feed into pairwise distance\n",
    "for i in range(df3.shape[1]): \n",
    "    df3.iloc[:,i]=df3.iloc[:,i].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise distances with the dice dissimilarity.\n",
    "m = pairwise_distances(df3, df3, metric='dice') \n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html\n",
    "#print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing. the missings here are false false values and creates negative inf val in dissimilarity matrix \n",
    "m_df=pd.DataFrame(m)\n",
    "keep=m_df.index[pd.isnull(m_df).any(axis=0)==False]\n",
    "m_df1=m_df.iloc[keep,keep]\n",
    "m_df1.shape\n",
    "m2=m_df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18925, 18925)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also delete these rows in original data with label in order to match with predictions\n",
    "df4=df2.iloc[keep,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform agglomerative clustering.\n",
    "# The affinity is precomputed (since the distance are precalculated).\n",
    "# Use an 'average' linkage. Use any other apart from  'ward'.\n",
    "agg = AgglomerativeClustering(n_clusters=6, affinity='precomputed',\n",
    "                              linkage='average')\n",
    "\n",
    "# Use the distance matrix directly.\n",
    "u = agg.fit_predict(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dendrogram\n",
    "#X = sp.spatial.distance.squareform(m2)\n",
    "#Z = cluster.hierarchy.linkage(X, 'average')\n",
    "\n",
    "#plt.figure()\n",
    "#dn = sp.cluster.hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5507162049822063"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.silhouette_score(m2, u, metric=\"precomputed\")\n",
    "#https://www.stat.berkeley.edu/~spector/s133/Clus.html\n",
    "#the cluster is weak and could potentially be artificial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabulate frequency for each prediction result \n",
    "unique_elements, counts_elements = np.unique(u, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1146, 10822,  5390,     1,  1561,     5])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18925"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aiyizhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10822, 31)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#associate prediction with original data \n",
    "df4['label']=u\n",
    "# only look at the second cluster\n",
    "df4_2=df4[df4.label==1] \n",
    "df4_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the percentage of true for each feature for label 2\n",
    "#label 2 seems to be the largest one so it could potentially be the likly cardiology patient \n",
    "hm2=[]\n",
    "for i in range(df4_2.iloc[:,:150].shape[1]):\n",
    "    hm2.append(round(np.unique(df4_2.iloc[:,:150].iloc[:,i], return_counts=True)[1][0]/df4_2.iloc[:,:150].shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm2=1-np.array(hm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm2=pd.DataFrame(list(map(list, zip(hm2, names.cat))))\n",
    "hm2=hm2.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm2.to_csv(\"~/Documents/persona_project_cardiology/clustering/hm2Aug24.csv\")\n",
    "\n",
    "#30 features\n",
    "#english speaking \n",
    "#middle aged (generation X) couple or single living by themselves without the presence of children\n",
    "#homeowner\n",
    "#voted\n",
    "#shop segment premium and high disposable income\n",
    "#direct mail responder \n",
    "\n",
    "#or middle class or old \n",
    "\n",
    "\n",
    "\n",
    "#150 features\n",
    "#no children\n",
    "#speaks english \n",
    "#homeowner, high disposable income \n",
    "#generation X\n",
    "#voted\n",
    "#apple app download\n",
    "\n",
    "#democrat\n",
    "#mid priced, and mid disposable income\n",
    "#live concert, dine out but not fastfood, alcohol\n",
    "#babyboomer \n",
    "#exercise \n",
    "\n",
    "\n",
    "#apparel website, amazon\n",
    "#uses phone, and does banking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot feature importance of label 2\n",
    "#sns.set(style=\"whitegrid\")\n",
    "#fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "#fig.set_size_inches(20, 8.27)\n",
    "\n",
    "#ax = sns.barplot(x=1, y=0, data=hm2[1:70],color=\"grey\", ax=ax)\n",
    "#ax.set_title('Percent Consumer per Feature for Likely Cardiolovescular Patients')\n",
    "#ax.set_xticklabels(ax.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmode\n",
    "#https://pypi.org/project/kmodes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "\n",
    "km = KModes(n_clusters=6, init='Huang', n_init=5, verbose=1)\n",
    "\n",
    "clusters = km.fit_predict(df3)\n",
    "\n",
    "# Print the cluster centroids\n",
    "#print(km.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['label']=clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at the second cluster\n",
    "df3_2=df3[df3.label==5] \n",
    "df3_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the percentage of true for each feature for label 2\n",
    "testk=[1]\n",
    "for i in range(df3_2.iloc[:,:150].shape[1]):\n",
    "    testk.append(round(np.unique(df3_2.iloc[:,:150].iloc[:,i], return_counts=True)[1][0]/df3_2.iloc[:,:150].shape[0],2))\n",
    "test_outk[:] = [1 - x  for x in test_outk]\n",
    "test_outk=pd.DataFrame(list(map(list, zip(testk, names.cat))))\n",
    "test_outk=test_outk.sort_values(by=[0], ascending=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outk.to_csv('kmode2Aug24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbscan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute DBSCAN use precomputed dissilimarity matrix \n",
    "db = DBSCAN(eps=0.3, min_samples=10,metric='precomputed').fit(m2)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(m2, labels, metric=\"precomputed\"))\n",
    "#lots of overlapping clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabulate frequency for each prediction result \n",
    "unique_elements, counts_elements = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#associate prediction with original data \n",
    "df5=df4\n",
    "df5['label']=labels\n",
    "# only look at the second cluster\n",
    "df5_2=df5[df5.label==1] \n",
    "df5_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the percentage of true for each feature for label 2\n",
    "#label 2 seems to be the largest one so it could potentially be the likly cardiology patient \n",
    "db=[]\n",
    "for i in range(df5_2.iloc[:,:150].shape[1]):\n",
    "    db.append(round(np.unique(df5_2.iloc[:,:150].iloc[:,i], return_counts=True)[1][1]/df5_2.iloc[:,:150].shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=pd.DataFrame(list(map(list, zip(db, names.cat))))\n",
    "db=db.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_csv(\"~/Documents/persona_project_cardiology/clustering/dbAug27.csv\")\n",
    "#very similar to hierarchical modeling\n",
    "\n",
    "#more than 40%: \n",
    "#no kids at home, single family, homeowner, residential building\n",
    "#english\n",
    "#high buying power able to afford premium goods\n",
    "#generation X \n",
    "#voted \n",
    "#apple app download\n",
    "#direct mail respondent \n",
    "#works out\n",
    "\n",
    "#30-40%: \n",
    "#babyboomer \n",
    "#don't keep a diet (dine out but not fastfood), live performance\n",
    "#average disposible income \n",
    "#democrat\n",
    "#apparel website \n",
    "\n",
    "#other\n",
    "#have cellphone service and banking service \n",
    "#shopping jewery\n",
    "#sight seeing, alcohol, self rate health management above average "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
